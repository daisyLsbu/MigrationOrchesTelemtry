{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grafana creation : queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter host in dependent variable:\n",
    "import \"influxdata/influxdb/v1\"\n",
    "v1.tagValues(\n",
    "    bucket: \"telemetryData\",\n",
    "    tag: \"host\",\n",
    "    predicate: (r) => true,\n",
    "    start: -1d\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "\n",
    "def connectToDB():\n",
    "  #token = 'UnZq8-3qAHW4bk5BNjZgPJLBeeNkOXWatintbu4RAZe_96fdRbPHofP_sE6JWNEPrTnGyFUg26ofUifZQx19DA=='\n",
    "  mac_token = \"tKQMaN6mMBXH-gDotw6qvpEOvcZNIMILQWTH1LTKFDddf3e4owp48cG88bFae1L_H3H5Tp8GV0jrDdzBjQiRhQ==\"\n",
    "  org = \"LSBU\"\n",
    "  url = \"http://localhost:8086\"\n",
    "\n",
    "  client = influxdb_client.InfluxDBClient(url=url, token=mac_token, org=org)\n",
    "  return client\n",
    "\n",
    "#absolute query\n",
    "query1 = \"\"\"\n",
    "    from(bucket:\"telemetryData\")\n",
    "    |> range(start: -1h)\n",
    "    \"\"\"\n",
    "\n",
    "#filter data on tables\n",
    "query2 = \"\"\"\n",
    "    from(bucket:\"telemetryData\")\n",
    "    |> range(start: -1h)\n",
    "    |> filter(fn: (r) => r._measurement == \"test7\")\n",
    "    \"\"\"\n",
    "\n",
    "#filter to get field data on tables\n",
    "query3 = \"\"\"\n",
    "    from(bucket:\"telemetryData\")\n",
    "    |> range(start: -1d)\n",
    "    |> filter(fn: (r) => r._measurement == \"test7\")\n",
    "    |> filter(fn: (r) => r._field == \"cpu_utilization\")\n",
    "    |> yield()\n",
    "    \"\"\"\n",
    "\n",
    "#filter to get tagdata on tables - not working\n",
    "query4 = \"\"\"\n",
    "    from(bucket:\"telemetryData\")\n",
    "    |> range(start: -1d)\n",
    "    |> filter(fn: (r) => r._measurement == \"test7\" and r.tag == \"host\")\n",
    "    |> filter(fn: (r) => r._field == \"cpu_utilization\")\n",
    "    |> yield()\n",
    "    \"\"\"\n",
    "\n",
    "#group by tag data on tables\n",
    "query5 = \"\"\"\n",
    "    from(bucket: \"telemetryData\")\n",
    "    |> range(start: -1d)\n",
    "    |> filter(fn: (r) => r._measurement == \"test7\")\n",
    "    |> filter(fn: (r) => r._field == \"cpu_utilization\")\n",
    "    |> group(columns: [\"host\"], mode: \"by\")\n",
    "    \"\"\"\n",
    "\n",
    "#group by tag data on tables\n",
    "query6 = \"\"\"\n",
    "    from(bucket: \"telemetryData\")\n",
    "\t|> range(start: -1d)\n",
    "    |> filter(fn: (r) => r[\"_measurement\"] == \"test101\")\n",
    "    |> filter(fn: (r) => r[\"_field\"] == \"host\")\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def runquery(client, query):\n",
    "  query_api = client.query_api()  \n",
    "  tables = query_api.query(query, org=\"LSBU\")\n",
    "\n",
    "  for table in tables:\n",
    "      for record in table.records:\n",
    "        print(record.values)\n",
    "        print(record)\n",
    "\n",
    "client = connectToDB()\n",
    "\n",
    "#writing data to db\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "   \n",
    "for value in range(5):\n",
    "  point = (\n",
    "    Point(\"measurement1\")\n",
    "    .tag(\"tagname1\", \"tagvalue1\")\n",
    "    .field(\"field1\", value)\n",
    "  )\n",
    "  write_api.write(bucket=bucket, org=\"LSBU\", record=point)\n",
    "  time.sleep(1) # separate points by 1 second\n",
    "\n",
    "#querying aggregated data from db\n",
    "query_api = client.query_api()\n",
    "\n",
    "query = \"\"\"from(bucket: \"telemetryData\")\n",
    "  |> range(start: -10m)\n",
    "  |> filter(fn: (r) => r._measurement == \"measurement1\")\n",
    "  |> mean()\"\"\"\n",
    "tables = query_api.query(query, org=\"LSBU\")\n",
    "\n",
    "for table in tables:\n",
    "    for record in table.records:\n",
    "        print(record)\n",
    "\n",
    "pp = PrettyPrinter(indent=2)\n",
    "\n",
    "def readFromDB(client, bucket):\n",
    "  # for each host query the DB to get the information\n",
    "  #querying data from db\n",
    "  query_api = client.query_api()  \n",
    "  query = \"\"\"\n",
    "  from(bucket: \"telemetryData\")\n",
    "\t|> range(start: -120m)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"test7\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"cpu_utilization\" or r[\"_field\"] == \"storage_free\" or r[\"_field\"] == \"vm_free\")\n",
    "  |> filter(fn: (r) => r[\"host\"] == \"10.35.109.155\")\n",
    "  \"\"\"\n",
    "  tables = query_api.query(query, org=\"LSBU\")\n",
    "  records = {}\n",
    "\n",
    "  for table in tables:\n",
    "      for record in table.records:\n",
    "        res[record['_field']] = record['_value']\n",
    "  records[\"10.35.109.155\"] = res\n",
    "  print(records)  \n",
    "\n",
    "  query = f'''\n",
    "    import \"influxdata/influxdb/v1\"\n",
    "    \n",
    "    data = from(bucket: \"{bucket}\")\n",
    "      |> range(start: -1d)\n",
    "      |> v1.tagValues(tag: \"host\")\n",
    "\n",
    "    distinctHosts = data |> group() |> distinct(column: \"host\")\n",
    "'''\n",
    "\n",
    "# Run the query\n",
    "result = client.query_api().query(org=org, query=query)\n",
    "\n",
    "# Extract and print the distinct tag values\n",
    "for table in result:\n",
    "    for record in table.records:\n",
    "        tag_value = record.values['host']\n",
    "        print(tag_value)\n",
    "\n",
    "# Close the client\n",
    "client.__del__()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get RTT data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pythonping import ping\n",
    "\n",
    "hosts = [\n",
    "    '8.8.8.8'\n",
    "]\n",
    "\n",
    "ping('8.8.8.8') \n",
    "[ping(host) for host in hosts]\n",
    "\n",
    "def ping_host(host):\n",
    "    ping_result = ping(target=host, count=10, timeout=2)\n",
    "\n",
    "    return {\n",
    "        'host': host,\n",
    "        'avg_latency': ping_result.rtt_avg_ms,\n",
    "        'min_latency': ping_result.rtt_min_ms,\n",
    "        'max_latency': ping_result.rtt_max_ms,\n",
    "        'packet_loss': ping_result.packet_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python async AIphttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with aiohttp.ClientSession() as session:\n",
    "        while True:\n",
    "            #create a collection of coroutines\n",
    "            fetch_coroutines = [fetch(session=session, url=url) for url in client_endpoints]\n",
    "\n",
    "            # fetch data\n",
    "            data = await asyncio.gather(*fetch_coroutines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python coding examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'value', 'k': 2, 'cc': {5: 8, 'p': 8}, '10.4.5.6': {'p': 8}}\n"
     ]
    }
   ],
   "source": [
    "#writing to dictionary\n",
    "\"\"\"_summary_\n",
    "\"\"\"\n",
    "s2 = {}\n",
    "s2.update({\"key\" : \"value\"})\n",
    "s2['k'] = 2\n",
    "s2['cc'] = {5:8}\n",
    "s2['cc'].update({'p':8})\n",
    "s2['10.4.5.6'] = {'h':5}\n",
    "s2['10.4.5.6'].update({'p':8})\n",
    "print(s2)\n",
    "\n",
    "#reading from dictionary of list and lisi of dictionary\n",
    "docker4 = [{'ctr':[{\"major\":254,\"minor\":0,\"op\":\"read\",\"value\":4096}, {\"major\":223,\"minor\":0,\"op\":\"read\",\"value\":4096}], 'Y':[4, 5, 6]}]\n",
    "print('docker4')\n",
    "\n",
    "for doc in docker4:\n",
    "  if 'ctr' in doc:\n",
    "    for k in doc['ctr']:\n",
    "        print(k['major'])\n",
    "\n",
    "\n",
    "#connecting API to get data\n",
    "def collectDataWithAPI(ip, port, k, result):\n",
    "    api_url = \"http://\" + ip + ':' + str(port) + \"/devicedetails\"\n",
    "    response = requests.get(api_url)\n",
    "    print(response.status_code )\n",
    "    if(response.status_code == 200):\n",
    "        deviceData = response.json()\n",
    "        result[k] = deviceData\n",
    "    else:\n",
    "        print(\"Error getting respose\")\n",
    "\n",
    "#reading csv and thread in list\n",
    "def allHostsData():\n",
    "    df = pd.read_csv('data/nodes.csv').transpose().to_dict()\n",
    "    result = {}\n",
    "    threads = [threading.Thread(target = collectDataWithAPI, args = (df[k][\"ip\"], df[k][\"port\"], k, result)) for k in df]\n",
    "    #threads = [threading.Thread(target = getCPUData, args = (n ,result)) for n in range(0, 10)]\n",
    "    [t.start() for t in threads]\n",
    "    [t.join() for t in threads]\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "#Creating class to be able to JSON encode\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "class testjsonencoder():\n",
    "    _len = 4\n",
    "    def __init__(self, atttr):\n",
    "        self.attr = atttr\n",
    "# subclass JSONEncoder\n",
    "class testEncoder(JSONEncoder):\n",
    "        def default(self, o):\n",
    "            return o.__dict__\n",
    "if __name__ == '__main__':\n",
    "    objtest = testjsonencoder(350)\n",
    "    jsonstring = json.dumps(objtest, cls= testEncoder)\n",
    "\n",
    "#to get Input\n",
    "import subprocess\n",
    "def subprocesswithinput():\n",
    "    host = input(\"Enter Host: \")\n",
    "   # packet = int(input(\"\\nEnter Packet: \"))\n",
    "    print(\"\\n\")\n",
    "    ping = subprocess.getoutput(f\"ping {host}\")\n",
    "    print(ping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker APIs and codes:\n",
    "for each container, exec any cmd, get container stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "client = docker.from_env()\n",
    "#container = client.containers.get(CONTAINER_ID)\n",
    "for container in client.containers.list():\n",
    "    exit_code, output = container.exec_run(\"ls\")\n",
    "    \n",
    "for containers in client.containers.list():\n",
    "        data = containers.stats(decode=None, stream = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python file for while, epoch, random and stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import os\n",
    "\n",
    "def startservice():\n",
    "        for epoch in range(10):\n",
    "            cpu = randint(1, 5)\n",
    "            io = randint(1, 3)\n",
    "            mem = randint(1, 10)\n",
    "            vm = randint(100, 300)\n",
    "\n",
    "            cmd = f\"\"\"\n",
    "                stress -c {cpu} -i {io} -m {mem} --vm-bytes {vm}M -t 10s\n",
    "                \"\"\"\n",
    "            os.system(cmd)\n",
    "            #stress -c 2 -i 1 -m 1 --vm-bytes 128M -t 10s\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    startservice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding stress component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stress ng commands\n",
    "#apt-get install stress\n",
    "#stress-ng <comp_option> <number> <time_option> <time> # multi options can be combined\n",
    "# uptime\n",
    "# stress -c 2 -i 1 -m 1 --vm-bytes 128M -t 10s\n",
    "# uptime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python flask - API creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.get(\"/getapi\")\n",
    "def get_combineddata():\n",
    "    return \"\"\n",
    "\n",
    "@app.route('/postwithreq', methods=['POST'])\n",
    "def rttData_json():\n",
    "    # Get JSON data from the request\n",
    "    data = request.get_json()\n",
    "    # Process the JSON data here (you can customize this part)\n",
    "    hosts = data[\"hosts\"]\n",
    "    return \"\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   app.run(host=\"0.0.0.0\") # to start on IP, not localhost\n",
    "\n",
    "def testPostAPI():\n",
    "    api_url = \"http://localhost:5000/rttData\"\n",
    "    data = {'hosts' : '192.168.100.2'}\n",
    "    response = requests.post(api_url, json={\n",
    "  \"hosts\": ['18.00', '192.0.3.4', '111', '123.9', '123']\n",
    "})\n",
    "\n",
    "    print(response.status_code )\n",
    "    if(response.status_code == 200):\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"Error getting respose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python - Thread programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading \n",
    "t1 = threading.Thread(target = cpu.getCPUData, args = ())\n",
    "t1.start()\n",
    "t1.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSUtil library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.net_io_counters().dropout\n",
    "psutil.disk_usage('/').percent\n",
    "psutil.virtual_memory().percent\n",
    "psutil.cpu_percent(interval=2)\n",
    "\n",
    "getattr(psutil.net_if_addrs(), \"snicaddr\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
